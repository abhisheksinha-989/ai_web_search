{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nGPfQSC-WK7_"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import http.client\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YOUCOM_API_KEY = \"\"\n",
        "SERPER_API_KEY = \"\"\n",
        "OPENROUTER_API_KEY = \"\"\n",
        "OPENROUTER_API_URL = \"https://openrouter.ai/api/v1/chat/completions\""
      ],
      "metadata": {
        "id": "0do67dPwWU20"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_with_openrouter(prompt, api_key=OPENROUTER_API_KEY, max_tokens=2000):\n",
        "    \"\"\"Generate response using Qwen 2.5 via OpenRouter API\"\"\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"HTTP-Referer\": \"https://github.com\",\n",
        "        \"X-Title\": \"Research Assistant\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"qwen/qwen-2.5-72b-instruct\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert research assistant. Provide detailed, factual answers based on given information.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"max_tokens\": max_tokens,\n",
        "        \"temperature\": 0.3\n",
        "    }\n",
        "    try:\n",
        "        response = requests.post(OPENROUTER_API_URL, headers=headers, json=payload, timeout=120)\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "        return result[\"choices\"][0][\"message\"][\"content\"] if \"choices\" in result else None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"OpenRouter API error: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "iyzGJwmOWWk8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_with_serper(query, api_key=SERPER_API_KEY):\n",
        "    \"\"\"Search with Serper API\"\"\"\n",
        "    conn = http.client.HTTPSConnection(\"google.serper.dev\")\n",
        "    payload = json.dumps({\"q\": query, \"num\": 10})\n",
        "    headers = {'X-API-KEY': api_key, 'Content-Type': 'application/json'}\n",
        "    try:\n",
        "        conn.request(\"POST\", \"/search\", payload, headers)\n",
        "        res = conn.getresponse()\n",
        "        return json.loads(res.read().decode(\"utf-8\"))\n",
        "    except Exception as e:\n",
        "        print(f\"Serper API error: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "cfW6dd6bWZm3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_with_youcom(query, api_key=YOUCOM_API_KEY):\n",
        "    \"\"\"Search with You.com API\"\"\"\n",
        "    headers = {'X-API-Key': api_key}\n",
        "    params = {'q': query, 'num_web_results': 10}\n",
        "    try:\n",
        "        response = requests.get('https://api.you.com/api/search', headers=headers, params=params, timeout=30)\n",
        "        return response.json()\n",
        "    except Exception as e:\n",
        "        print(f\"You.com API error: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "V0a71VOxWcCI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_search_results(serper_data, youcom_data):\n",
        "    \"\"\"Extract unique search results\"\"\"\n",
        "    results = []\n",
        "    if serper_data and 'organic' in serper_data:\n",
        "        for result in serper_data['organic'][:5]:\n",
        "            results.append({'title': result.get('title', ''), 'snippet': result.get('snippet', ''), 'link': result.get('link', ''), 'source': 'Serper'})\n",
        "    if youcom_data and 'hits' in youcom_data:\n",
        "        for hit in youcom_data['hits'][:5]:\n",
        "            results.append({'title': hit.get('title', ''), 'snippet': hit.get('description', ''), 'link': hit.get('url', ''), 'source': 'You.com'})\n",
        "    unique_results = []\n",
        "    seen_titles = set()\n",
        "    for result in results:\n",
        "        title_key = result['title'].lower()[:100]\n",
        "        if title_key not in seen_titles:\n",
        "            seen_titles.add(title_key)\n",
        "            unique_results.append(result)\n",
        "    return unique_results"
      ],
      "metadata": {
        "id": "v-y6TxfKWfRc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_context(results):\n",
        "    \"\"\"Create context from search results\"\"\"\n",
        "    context_parts = [f\"RESULT {i+1}:\\nTITLE: {r['title']}\\nCONTENT: {r['snippet']}\\nSOURCE: {r['source']}\\nURL: {r['link']}\\n\" for i, r in enumerate(results[:8])]\n",
        "    return \"\\n\".join(context_parts)[:3000]"
      ],
      "metadata": {
        "id": "OLn5CAoIWhu5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt(query, context):\n",
        "    \"\"\"Create a detailed, universal prompt for all query types\"\"\"\n",
        "    return f\"\"\"You are an expert AI research assistant tasked with providing comprehensive, accurate, and well-structured answers based solely on the provided search results. Adapt your response to the query type for optimal relevance and clarity.\n",
        "\n",
        "QUERY: {query}\n",
        "\n",
        "SEARCH RESULTS:\n",
        "{context}\n",
        "\n",
        "RESPONSE GUIDELINES:\n",
        "\n",
        "1. **Query Type Adaptation**:\n",
        "   - **Technical/Coding Queries**: Provide detailed code examples with explanations, best practices, and error handling.\n",
        "   - **General Knowledge**: Offer a thorough overview with specific facts, historical context, and examples.\n",
        "   - **Research/Academic**: Use a formal tone, structured analysis, and cite sources explicitly (e.g., \"Source: [URL]\").\n",
        "   - **How-To/Instructional**: Provide clear, step-by-step instructions with practical tips and potential pitfalls.\n",
        "   - **Comparative Queries**: Present a balanced comparison with pros, cons, and key differentiators in a table format if applicable.\n",
        "\n",
        "2. **Response Structure**:\n",
        "   - Start with a concise, direct answer to the query.\n",
        "   - Organize content into logical sections with descriptive headings.\n",
        "   - Use bullet points or numbered lists for clarity and readability.\n",
        "   - Include specific details such as numbers, dates, names, or technical specifications when available.\n",
        "\n",
        "3. **Content Requirements**:\n",
        "   - Base the response strictly on the provided search results; do not speculate or add external information.\n",
        "   - If information is missing or limited, explicitly state: \"The provided search results do not contain enough information to fully answer this query.\"\n",
        "   - Include practical examples or real-world applications where relevant.\n",
        "   - For sensitive topics (e.g., medical, legal), include a disclaimer: \"This information is not a substitute for professional advice.\"\n",
        "\n",
        "4. **Formatting**:\n",
        "   - Use markdown for clear formatting (e.g., **bold** for emphasis, `code` blocks for programming).\n",
        "   - Include tables for comparisons or structured data.\n",
        "   - Use consistent section headings and avoid overly verbose language.\n",
        "   - For code, specify the programming language and ensure syntax accuracy.\n",
        "\n",
        "5. **Special Cases**:\n",
        "   - **Coding Queries**: Provide complete, runnable code with comments explaining key sections.\n",
        "   - **Current Events**: Focus on the most recent information from the results, noting dates where available.\n",
        "   - **Subjective Topics**: Present multiple perspectives neutrally, citing sources for each viewpoint.\n",
        "   - **Complex Queries**: Break down the response into sub-questions or components for clarity.\n",
        "\n",
        "6. **Accuracy and Transparency**:\n",
        "   - Prioritize factual accuracy over completeness; do not fill gaps with assumptions.\n",
        "   - If results are contradictory, highlight inconsistencies and explain which source is more reliable, if possible.\n",
        "   - Cite sources by referencing their URLs or titles as provided in the search results.\n",
        "\n",
        "RESPONSE:\"\"\""
      ],
      "metadata": {
        "id": "wMkX36jzWkyH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_research_answer(query):\n",
        "    \"\"\"Get research answer using search APIs and OpenRouter\"\"\"\n",
        "    serper_data = search_with_serper(query)\n",
        "    youcom_data = search_with_youcom(query)\n",
        "    results = extract_search_results(serper_data, youcom_data)\n",
        "    if not results:\n",
        "        print(\"No search results found.\")\n",
        "        return None, []\n",
        "    context = create_context(results)\n",
        "    prompt = create_prompt(query, context)\n",
        "    summary = generate_with_openrouter(prompt)\n",
        "    return summary, results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    query = \"What are the best LLMs developed to date?\"\n",
        "    start_time = time.time()\n",
        "    summary, sources = get_research_answer(query)\n",
        "    end_time = time.time()\n",
        "    if summary:\n",
        "        print(\"=\"*50)\n",
        "        print(\"RESEARCH REPORT\")\n",
        "        print(\"=\"*50)\n",
        "        print(summary)\n",
        "        print(f\"\\nStats: {len(summary.split())} words, {end_time - start_time:.2f}s\")\n",
        "        print(\"\\nSOURCES\")\n",
        "        for i, source in enumerate(sources[:5]):\n",
        "            print(f\"\\nSource {i+1} ({source['source']}):\")\n",
        "            print(f\"Title: {source['title']}\")\n",
        "            print(f\"URL: {source['link']}\")\n",
        "    else:\n",
        "        print(\"Failed to generate report.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn8YOBwYWoJ1",
        "outputId": "e794a129-08f3-4579-f145-fd73c9bcee13"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "RESEARCH REPORT\n",
            "==================================================\n",
            "### Best Large Language Models (LLMs) Developed to Date\n",
            "\n",
            "Based on the provided search results, several large language models (LLMs) stand out as leading contenders in terms of capabilities, performance, and application. Here is a comprehensive overview of the best LLMs as of 2025:\n",
            "\n",
            "#### 1. **GPT-4**\n",
            "- **Provider**: OpenAI\n",
            "- **Capabilities**: Known for its advanced natural language understanding, generation, and reasoning abilities. It excels in a wide range of tasks, including text summarization, translation, and complex problem-solving.\n",
            "- **Context Window**: Supports longer context windows, allowing it to handle more extensive and nuanced conversations.\n",
            "- **Price**: Commercially available with varying pricing tiers based on usage.\n",
            "- **Source**: [Zapier](https://zapier.com/blog/best-llm/)\n",
            "\n",
            "#### 2. **Claude 4**\n",
            "- **Provider**: Anthropic\n",
            "- **Capabilities**: Praised for its writing capabilities, project features, and the ability to generate diverse and customized content. It is particularly strong in creative writing and generating artifacts.\n",
            "- **Context Window**: Offers a robust context window, enabling it to maintain coherence over longer interactions.\n",
            "- **Price**: Commercially available with flexible pricing options.\n",
            "- **Source**: [Reddit](https://www.reddit.com/r/singularity/comments/1impsjl/what_is_your_favorite_llm_right_now/) and [Zapier](https://zapier.com/blog/best-llm/)\n",
            "\n",
            "#### 3. **PaLM 2**\n",
            "- **Provider**: Google DeepMind\n",
            "- **Capabilities**: Known for its versatility and high performance in various NLP tasks. It has been optimized for efficiency and can handle a broad spectrum of applications, from chatbots to content creation.\n",
            "- **Context Window**: Supports extended context windows, enhancing its ability to understand and respond to complex queries.\n",
            "- **Price**: Commercially available through Google Cloud services.\n",
            "- **Source**: [Botpress](https://botpress.com/blog/best-large-language-models)\n",
            "\n",
            "#### 4. **Llama 2**\n",
            "- **Provider**: Meta\n",
            "- **Capabilities**: Strong in multilingual support and general-purpose language tasks. It is designed to be highly adaptable and can be fine-tuned for specific use cases.\n",
            "- **Context Window**: Offers a significant context window, making it suitable for long-form content and detailed interactions.\n",
            "- **Price**: Available both commercially and as an open-source model.\n",
            "- **Source**: [Botpress](https://botpress.com/blog/best-large-language-models)\n",
            "\n",
            "#### 5. **DeepSeek**\n",
            "- **Provider**: DeepSeek\n",
            "- **Capabilities**: Specializes in search and retrieval tasks, integrating seamlessly with existing search engines and databases to provide accurate and relevant information.\n",
            "- **Context Window**: Efficient context handling, though specifics are not detailed in the provided results.\n",
            "- **Price**: Commercially available with enterprise-focused pricing.\n",
            "- **Source**: [Botpress](https://botpress.com/blog/best-large-language-models)\n",
            "\n",
            "#### 6. **xAI**\n",
            "- **Provider**: xAI\n",
            "- **Capabilities**: Focuses on interpretability and transparency, making it easier to understand how the model makes decisions. Ideal for applications requiring explainable AI.\n",
            "- **Context Window**: Not specified in the provided results.\n",
            "- **Price**: Commercially available with pricing details not provided.\n",
            "- **Source**: [Botpress](https://botpress.com/blog/best-large-language-models)\n",
            "\n",
            "#### 7. **Mistral**\n",
            "- **Provider**: Mistral\n",
            "- **Capabilities**: Known for its high performance in generative tasks and its ability to produce coherent and contextually relevant responses.\n",
            "- **Context Window**: Supports extended context windows, though exact figures are not provided.\n",
            "- **Price**: Commercially available with pricing details not provided.\n",
            "- **Source**: [Botpress](https://botpress.com/blog/best-large-language-models)\n",
            "\n",
            "#### Open-Source LLMs\n",
            "Open-source LLMs offer the advantage of transparency and flexibility, allowing researchers and developers to modify and improve the models. Some notable open-source LLMs include:\n",
            "\n",
            "- **BLOOM**\n",
            "  - **Provider**: BigScience\n",
            "  - **Capabilities**: Multilingual and versatile, suitable for a wide range of NLP tasks.\n",
            "  - **Context Window**: Not specified in the provided results.\n",
            "  - **Price**: Free and open-source.\n",
            "  - **Source**: [Vellum AI](https://www.vellum.ai/llm-leaderboard)\n",
            "\n",
            "- **Galactica**\n",
            "  - **Provider**: Meta\n",
            "  - **Capabilities**: Specialized in scientific and technical domains, providing accurate and detailed responses.\n",
            "  - **Context Window**: Not specified in the provided results.\n",
            "  - **Price**: Free and open-source.\n",
            "  - **Source**: [Vellum AI](https://www.vellum.ai/llm-leaderboard)\n",
            "\n",
            "#### Comparative Analysis\n",
            "To help you make an informed decision, here is a comparative table of the leading LLMs:\n",
            "\n",
            "| Model      | Provider       | Capabilities                                      | Context Window | Price                |\n",
            "|------------|---------------|--------------------------------------------------|----------------|----------------------|\n",
            "| GPT-4      | OpenAI        | Advanced NLP, problem-solving, creativity         | Extended        | Commercial            |\n",
            "| Claude 4   | Anthropic     | Writing, project features, customization           | Robust          | Commercial            |\n",
            "| PaLM 2     | Google DeepMind | Versatile, efficient, high performance             | Extended        | Commercial (Google Cloud) |\n",
            "| Llama 2    | Meta          | Multilingual, adaptable, fine-tuning               | Significant     | Commercial/Open-source |\n",
            "| DeepSeek   | DeepSeek      | Search and retrieval, integration with databases   | Efficient       | Commercial (Enterprise) |\n",
            "| xAI        | xAI           | Interpretability, transparency                     | Not specified   | Commercial            |\n",
            "| Mistral    | Mistral       | High performance, generative tasks                 | Extended        | Commercial            |\n",
            "| BLOOM      | BigScience    | Multilingual, versatile                            | Not specified   | Free (Open-source)    |\n",
            "| Galactica  | Meta          | Scientific and technical domains                   | Not specified   | Free (Open-source)    |\n",
            "\n",
            "#### Conclusion\n",
            "The best LLMs developed to date vary in their strengths and applications. GPT-4 and Claude 4 are highly regarded for their advanced capabilities and writing prowess, while PaLM 2 and Llama 2 offer versatility and efficiency. Open-source models like BLOOM and Galactica provide transparency and flexibility, making them valuable for research and development. The choice of LLM depends on the specific needs of your project, such as the required level of customization, domain expertise, and budget constraints.\n",
            "\n",
            "For more detailed benchmarks and comparisons, refer to the [Vellum AI LLM Leaderboard](https://www.vellum.ai/llm-leaderboard) and [TechRadar's Best LLMs of 2025](https://www.techradar.com/computing/artificial-intelligence/best-llms).\n",
            "\n",
            "Stats: 820 words, 46.81s\n",
            "\n",
            "SOURCES\n",
            "\n",
            "Source 1 (Serper):\n",
            "Title: LLM Leaderboard 2025 - Vellum AI\n",
            "URL: https://www.vellum.ai/llm-leaderboard\n",
            "\n",
            "Source 2 (Serper):\n",
            "Title: Best Large Language Models (LLMs) of 2025 - TechRadar\n",
            "URL: https://www.techradar.com/computing/artificial-intelligence/best-llms\n",
            "\n",
            "Source 3 (Serper):\n",
            "Title: The best large language models (LLMs) in 2025 - Zapier\n",
            "URL: https://zapier.com/blog/best-llm/\n",
            "\n",
            "Source 4 (Serper):\n",
            "Title: What is your favorite LLM right now? : r/singularity - Reddit\n",
            "URL: https://www.reddit.com/r/singularity/comments/1impsjl/what_is_your_favorite_llm_right_now/\n",
            "\n",
            "Source 5 (Serper):\n",
            "Title: The 10 Best Large Language Models (LLMs) in 2025 - Botpress\n",
            "URL: https://botpress.com/blog/best-large-language-models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xUuLl96xWsAl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}